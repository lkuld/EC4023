---
title: "Tutorial 4: Functions and pipelines"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(EC4023)
library(stringr)
library(dplyr)
knitr::opts_chunk$set(echo = FALSE)
```


##  Functions

In Tutorial 1, you used and wrote a simple function. In this tutorial, we look more closely at functions and how to apply multiple functions efficiently to subset data and calculate group-specific statistics.

Recall the function from Tutorial 1: $f(x)=4x+3$. It returns a numeric output for a given input $x$.


```{r FunktionBsp, exercise=TRUE}

linearFunction <- function(x){
  4*x + 3
}

linearFunction(x =2)
linearFunction(2)
```

This function has one argument, x. We can also write a function with two arguments. For example, the mean of two numbers red and blue is
$f(\text{red}, \text{blue})=\frac{\text{red}+\text{blue}}{2}$.

If you do not want to perform all calculations in one line, save intermediate results, as in `mean2` below. These intermediates exist only inside the function environment.

```{r f2, exercise=TRUE}

mean2 <- function(red, blue){
  sum <- red+blue
  mean <- sum/2
  mean
}

mean2(red=2, blue = 4)
```

If you want to find out what a function does or what arguments it takes, type ?function, in the console, e.g. `?log`. 

`log(x)` computes a logarithm with base `exp(1)=e` by default, that is `log(x)=log(x, base = exp(1))`. Like many other functions, `log()` has a default setting for one of its arguments, that is the base is set to `exp(1)` (Euler's number). 

**Task:**  Change the base to 10 in the box below.

```{r log, exercise=TRUE}

log(5)
```
```{r log-solution}

log(5, base = 10)
```

## Pipelines

Often, we want to apply more than one function  to a dataset. A common case might be to first subset the data and then calculate a statistic. If we do not want to save all intermediate results, we can apply multiple functions at once. To make this approach more readable, the pipeline operator helps to separate out the different steps/functions.

In the example below, we first change a vector to numeric, then calculate the natural logarithm of each number, and finally calculate the mean.

```{r f3, exercise=TRUE}

vec <- c('3', '5', '2', '8')
vec2 <- as.numeric(vec)
vec3 <- log(vec2)
vec4 <- mean(vec3)
vec4

mean(log(as.numeric(vec)))
```

The first approach is very long and we either have to overwrite our initial vector or create  a lot of objects. The second approach is hard to read.

Instead, we can use a 'pipeline' operator. R has two pipeline operators, the newer base R operator `|>` and the older `%>%` from the `margittr` package (You will see both used frequently in online/GenAI solutions). They are mostly interchangeable.

The next box demonstrates the approach. The output of each step becomes the first argument in the next step, that is `x |> f(y)` is the same as `f(x, y)`. 

A quick way to type ` |> ` in RStduio is to press Ctrl+Shift+M at the same time (You can change in the Code settings whether you want the base or margittr pipeline operator). Type ?'|>' for more details.

```{r f4, exercise=TRUE}

vec <- c('3', '5', '2', '8')


m <- vec |>
  as.numeric() |> 
  log() |> 
  mean()
  
m


```

## dplyr

`dplyr` is a an R package for data manipulation that uses the pipeline structure.^[See https://dplyr.tidyverse.org/ or vignette("dplyr") in R.] Here we cover the core ideas only. For a more in-depth introduction on the various functions and help see https://r4ds.had.co.nz/transform.html.

Recall the cleaned Limerick housing data from Tutorial 2: all property-price records for Limerick from 2018 to 2022.

```{r dat}
limerick_property_df
```

Using base R and `dplyr`, we will calculate the mean price for all observations from 2019. (The package `dplyr` is already loaded here, use `library(dplyr)` first to run the code outside this tutorial.)

```{r f5, exercise=TRUE}

mean2019_base <- limerick_property_df[limerick_property_df$year == '2019', 'price'] |> 
  mean() 

mean2019_dplyr <- limerick_property_df |>
  filter(year == '2019') |> 
  summarise(mean = mean(price)) 

mean2019_base
mean2019_dplyr
```

`dplyr` reads closer to natural language, which helps understanding and writing more complex code.

A useful application of the `dplyr` structure is calculating statistics by group using the `group_by()` function. The code below returns the mean price and number of observations by year.

```{r f6, exercise=TRUE}

mean2019_dplyr <- limerick_property_df |>
  group_by(year) |> 
  summarise(mean = mean(price), 
            n=n()) 

mean2019_dplyr
```

We can easily calculate more statistics by group and also add a filter.

**Task:**   Calculate the (a) mean price, (b) median price, (c) price standard deviation, and (d) number of observations, each by year and only for observations under 500,000 euro.

```{r f7, exercise=TRUE}

```
```{r f7-solution}

under500k <- limerick_property_df |> 
  filter(price<500000) |> 
  group_by(year) |> 
  summarise(mean=mean(price), median=median(price), std.dev=sd(price), n=n())

under500k

```


Instead of creating a new data set for the summary statistics, you could replace the function `summarise` with `mutate` to add the new statistics as variables to the old data.frame. 

**Task:**   Use the box below to create a new logical `TRUE`/`FALSE` variable. The new variable, called 'expensive' should have the value true if the price is larger than the median price of the year.


```{r f8, exercise=TRUE}

```
```{r f8-solution}

limerick_property_df <- limerick_property_df |> 
  group_by(year) |> 
  mutate(expensive = price > median(price))

limerick_property_df

```

Run the tutorials ex-data-filter, ex-data-mutate, and ex-data-summarise in the `learnr` package for more tutorials on these operations. Type `learnr::run_tutorial(name = 'ex-data-filter', package = 'learnr')`, `learnr::run_tutorial(name = 'ex-data-mutate', package = 'learnr')`, or `learnr::run_tutorial(name = 'ex-data-summarise', package = 'learnr')`.
